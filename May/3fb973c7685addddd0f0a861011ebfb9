The younger company is in prime position. It doesn't require the infrastructure of the soft-drink company, or have to buy raw materials and packaging, build and operate bottling plants (or partner with companies that do), or transport cooldrinks over vast distances to deliver the same product in the same-shaped bottle or can every time.It seems like a lot of work for what are currently poor results, while Facebook is making money for jam.But the social-media giant is now under pressure as it tries to fend off a backlash over the content it allows - content no other publishing company could get away with.Racism, sexism, abuse, bullying - all available on its platform in graphic detail.The horrifying content included a recent death threat a friend received on Facebook from a fake profile.It might have come across to those at the company who review complaints as insignificant, which was why she was told it did not violate their community standards.But to our community it was serious, and Facebook's initial refusal to delete the post made me wonder just what value this company has when it enables vitriol to spread so fast and furiously.A report published last weekend by The Guardian, following an investigation into Facebook, revealed just how much it lets slide."Facebook tells moderators to err on the side of allowing content if they are unsure," The Guardian reported.And it seems many of them are unsure, because there aren't enough moderators and they do not appear to be properly trained to deal with abusive content.Facebook will hire 3000 more people - over and above the 4500 already employed - to review reported content. It would not disclose how many would be based in South Africa, but with close to two billion users, regardless of where these moderators are, it's a paltry number of people.Facebook also relies on users to report content and automated screening systems. But the volume of work is overwhelming. For example, Facebook reviews more than 6.5 million reports a week of possible fake profiles. This a fraction of the number of individual reports on specific content.One source told The Guardian: "Facebook cannot keep control of its content. It has grown too big, too quickly."Facebook's denials that it is not a publishing company is akin to a newspaper publisher claiming it is only a printer. Facebook prefers the term "technology company", saying it does not control the content published on its site.It's obvious why: media companies are responsible for making sure the content published is balanced, fair and accurate. And there are consequences if they fail to uphold those standards.For a company that lauds itself for being a platform that enables open debate, and therefore promotes a transparent society, it sticks in the throat when it is secretive about its operations.If the company won't up its game (it says it's trying and has a plan), governments, civil society and users need to force it do so.Elsewhere, there is increasing pressure to fine social-media companies if they do not remove offensive content quickly. So incensed were officials over Facebook's poor controls that one Labour MP in the UK accused it of commercial prostitution.It seems fines and regulation may be the only way to get social-media companies to take their responsibilities more seriously.Neither Coca-Cola's products nor Facebook's are good for you, yet both are consumed voraciously.With Facebook just 13 years old and Coca-Cola 131, I wonder which company's fizz will last longest.Enslin-Payne is deputy editor of Business Times